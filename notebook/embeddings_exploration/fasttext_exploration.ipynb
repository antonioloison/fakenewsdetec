{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/antonioloison/Projects/fakenewsdetec'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/antonioloison/Projects/fakenewsdetec\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from typing import Dict, List\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fake_news = pd.read_csv(\"data/Fake.csv\")\n",
    "true_news = pd.read_csv(\"data/True.csv\")\n",
    "print(fake_news.shape)\n",
    "print(true_news.shape)\n",
    "\n",
    "fake_news[\"label\"] = \"fake\"\n",
    "true_news[\"label\"] = \"true\"\n",
    "\n",
    "train_news = pd.concat([fake_news, true_news]).reset_index(drop=True).sample(frac=1).reset_index(drop=True)\n",
    "train_news.shape\n",
    "\n",
    "train_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4138, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news = pd.read_csv(\"data/train_berkeley_1.csv\")\n",
    "val_news = pd.read_csv(\"data/eval_berkeley_1.csv\")\n",
    "test_news = pd.read_csv(\"data/test_berkeley_1.csv\")\n",
    "train_news = train_news[[\"title\", \"text\", \"label\"]]\n",
    "train_news[\"processed_text\"] = train_news[\"text\"]\n",
    "train_news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Reuters bias"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def clean_reuters(row):\n",
    "    text = row[\"text\"]\n",
    "    label = row[\"label\"]\n",
    "    if label == \"true\":\n",
    "        splitted_text = text.split(\"-\")\n",
    "        if splitted_text:\n",
    "            if \"(Reuters)\" in splitted_text[0]:\n",
    "                return \"-\".join(splitted_text[1:])\n",
    "        return \"-\".join(splitted_text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_news[\"processed_text\"] = train_news.apply(clean_reuters, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "# NLP Preprocessing\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news[\"processed_text\"] = train_news[\"text\"].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "test_news[\"processed_text\"] = test_news[\"text\"].apply(lambda x: ' '.join(simple_preprocess(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news[\"processed_label\"] = train_news[\"label\"].apply(lambda x: '__label__' + str(x))\n",
    "test_news[\"processed_label\"] = test_news[\"label\"].apply(lambda x: '__label__' + str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>processed_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memorial Day provides respite from VA controve...</td>\n",
       "      <td>Memorial Day is a time to remember those who g...</td>\n",
       "      <td>0</td>\n",
       "      <td>memorial day is time to remember those who gav...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marco Rubio, announcing 2016 campaign, focuses...</td>\n",
       "      <td>It’s not that Americans won’t elect wealthy pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>it not that americans won elect wealthy presid...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prepare Yourself For The Higher Energies</td>\n",
       "      <td>Leave a reply \\nDylan Harper – Everything and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>leave reply dylan harper everything and everyo...</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Place your bets now. How much does someone’s w...</td>\n",
       "      <td>Dan Kahan and his team at the Yale Law School’...</td>\n",
       "      <td>0</td>\n",
       "      <td>dan kahan and his team at the yale law school ...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gay marriage ruling leaves debate about religi...</td>\n",
       "      <td>The Supreme Court made a number of important d...</td>\n",
       "      <td>0</td>\n",
       "      <td>the supreme court made number of important dec...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Memorial Day provides respite from VA controve...   \n",
       "1  Marco Rubio, announcing 2016 campaign, focuses...   \n",
       "2           Prepare Yourself For The Higher Energies   \n",
       "3  Place your bets now. How much does someone’s w...   \n",
       "4  Gay marriage ruling leaves debate about religi...   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Memorial Day is a time to remember those who g...      0   \n",
       "1  It’s not that Americans won’t elect wealthy pr...      0   \n",
       "2  Leave a reply \\nDylan Harper – Everything and ...      1   \n",
       "3  Dan Kahan and his team at the Yale Law School’...      0   \n",
       "4  The Supreme Court made a number of important d...      0   \n",
       "\n",
       "                                      processed_text processed_label  \n",
       "0  memorial day is time to remember those who gav...      __label__0  \n",
       "1  it not that americans won elect wealthy presid...      __label__0  \n",
       "2  leave reply dylan harper everything and everyo...      __label__1  \n",
       "3  dan kahan and his team at the yale law school ...      __label__0  \n",
       "4  the supreme court made number of important dec...      __label__0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the CSV file as a text file to train/test the classifier\n",
    "train_news[['processed_label', 'processed_text']].to_csv('data/train.txt', \n",
    "                                          index = False, \n",
    "                                          sep = ' ',\n",
    "                                          header = None, \n",
    "                                          quoting = csv.QUOTE_NONE, \n",
    "                                          quotechar = \"\", \n",
    "                                          escapechar = \" \")\n",
    "\n",
    "test_news[['processed_label', 'processed_text']].to_csv('data/test.txt', \n",
    "                                     index = False, \n",
    "                                     sep = ' ',\n",
    "                                     header = None, \n",
    "                                     quoting = csv.QUOTE_NONE, \n",
    "                                     quotechar = \"\", \n",
    "                                     escapechar = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "# Skipgram model :\n",
    "model = fasttext.train_supervised('data/train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(887, 0.7316798196166855, 0.7316798196166855)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test('data/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top five clinton donors are jewish how anti semitic is this fact published october source moon of alabama top five clinton donors are jewish campaign tally shows something is wrong with the above statement isn it anti semitic did trump say that readers of that statement may assume somewhat reasonably that there is club of rich jewish people controlling the clinton campaign and maybe clinton herself that sounds like it was taken from the fake protocols of the elders of zion it clearly must be anti semitic it is also true facts have no bias they can be anti semitic or can they but while facts as such can not have racial religious bias openly stating them surely can thus the above statement is anti semitic the fact itself isn bad reporting it publicly is bad bad bad who but an alt right rag would report such at all and for what purpose if not for spreading anti semitism well quot licet jovi jewish papers are of course allowed to report such fact that isn anti semitic it is solely to brag about jewish powers within the club that is not only allowed but welcome thus haaretz writes sourced to the the jewish telegraph agency under the identity defining headline at the top of this post haim saban george soros and others stand at the head of list of wealthy donors who contributed mainly via super pacs the washington post analysis posted october named the top donors who are contributing of every of the over billion amassed for the democratic nominee presidential run they are donald sussman hedge fund manager pritzker venture capitalist and his wife haim saban the israeli american entertainment mogul and his wife cheryl george soros another hedge funder and major backer of liberal causes and daniel abraham backer of liberal pro israel causes and the founder of slimfast many of the big clinton campaign donors also give to the clinton foundation which at times is washing machine to put money into the clinton private accounts it is kind of difficult to understand where clinton inc begins and where it ends campaign funds clinton foundation speech fees private accounts does it even matter surely those who pay to whatever clinton entity expect service in return given the clinton occupations as senator secretary of state and president the ask in return is unlikely to be commercial it will be political and here is why it matters that the five top donors to clinton campaign are jewish and all big supporters of israel haim saban one issue guy and my issue is israel they surely will ask for political favors in the interest of the zionist entity this is also the reason why haaretz an israeli paper finds the strong racial religious bias at the top clinton campaign tally newsworthy big money paid to clinton entity can directly effect policies towards israel it buys its acquiescence to israeli escapades even when those are not consistent interests clinton positions towards syria iran and russia which limits israel freedom of action are surely not independent of israeli interests but that is of course anti semitic speculation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_news.iloc[0,-2])\n",
    "#print(list(test_df.iloc[:3,-1]))\n",
    "preds = model.predict(list(test_news.iloc[:3,-1]))[0]\n",
    "[int(pred[0].split(\"__\")[2]) for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_data: pd.DataFrame):\n",
    "    texts = list(test_data[\"processed_text\"])\n",
    "    print(len(texts))\n",
    "    #print(texts[:10])\n",
    "    predictions = model.predict(texts)[0]\n",
    "    return [int(pred[0].split(\"__\")[2]) for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887\n"
     ]
    }
   ],
   "source": [
    "preds = predict(model, test_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(test_news[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2085\n",
       "1    2053\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fakenewsdetec.model.fasttext_classifier import FasttextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = FasttextClassifier({\"saved_model_path\": \"\",\n",
    "                          \"train\": \"True\"},\n",
    "                         train_news,\n",
    "                         val_news,\n",
    "                         test_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_metrics': {'accuracy': 0.7535041082648622,\n",
       "  'recall': 0.5776911836337068,\n",
       "  'precision': 0.8857356235997013,\n",
       "  'f1-score': 0.6992924528301887,\n",
       "  'support': [2085, 2053]},\n",
       " 'validation_metrics': {'accuracy': 0.7440811724915445,\n",
       "  'recall': 0.5570469798657718,\n",
       "  'precision': 0.89568345323741,\n",
       "  'f1-score': 0.6868965517241379,\n",
       "  'support': [440, 447]},\n",
       " 'test_metrics': {'accuracy': 0.7373167981961668,\n",
       "  'recall': 0.5375586854460094,\n",
       "  'precision': 0.8641509433962264,\n",
       "  'f1-score': 0.662807525325615,\n",
       "  'support': [461, 426]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.compute_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difficult dataset!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"/Volumes/Elements SE/crawl-300d-2M-subword.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "from gensim.models.fasttext import load_facebook_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(\"/Users/antonioloison/Documents/wiki-news-300d-1M-subword.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('desks', 0.8139737844467163), ('desk-', 0.8030417561531067), ('desk.', 0.778192400932312), ('front-desk', 0.7296270132064819), ('ref-desk', 0.7272905111312866), ('deskside', 0.7197455167770386), ('help-desk', 0.715452253818512), ('writing-desk', 0.7056628465652466), ('refdesk', 0.6872211694717407), ('Desk', 0.6861226558685303)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar('desk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999994\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for word in model.vocab:\n",
    "    words.append(word)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector components of a word: 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector components of a word: {}\".format(\n",
    "    len(model[words[0]])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def sent_vectorizer(sent, model):\n",
    "    sent_vec =[]\n",
    "    numw = 0\n",
    "    for w in sent:\n",
    "        try:\n",
    "            if numw == 0:\n",
    "                sent_vec = model[w]\n",
    "            else:\n",
    "                sent_vec = np.add(sent_vec, model[w])\n",
    "            numw+=1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return np.asarray(sent_vec) / numw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f95af415ef3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "V=[]\n",
    "for sentence in list():\n",
    "    V.append(sent_vectorizer(sentence, model)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
